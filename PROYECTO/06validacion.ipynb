{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97428fea",
   "metadata": {},
   "source": [
    "# Evaluación del Modelo de Clasificación\n",
    "\n",
    "Este notebook evalúa el desempeño de un modelo de clasificación entrenado para predecir la reprobación de estudiantes en Biología. Se comparan los resultados entre los conjuntos de entrenamiento y prueba utilizando métricas clave como Accuracy, Matriz de Confusión, Reporte de Clasificación, y AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee056c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv(\"1DATABASE1.csv\", sep=';')\n",
    "\n",
    "# Preprocesamiento básico\n",
    "df['Nota 1'] = df['Nota 1'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['Nota 2'] = df['Nota 2'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['APROBADO/REPROBADO'] = df['APROBADO/REPROBADO'].map({'APROBADO': 1, 'REPROBADO': 0})\n",
    "\n",
    "X = df[['Nota 1', 'Nota 2', 'Asistencia Clases (%)', 'Asistencia Laboratorio (%)']]\n",
    "y = df['APROBADO/REPROBADO']\n",
    "\n",
    "# Dividir en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenar modelo\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_train_pred = modelo.predict(X_train)\n",
    "y_test_pred = modelo.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy (entrenamiento):\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Accuracy (test):\", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Reportes\n",
    "print(\"\\nReporte entrenamiento:\\n\", classification_report(y_train, y_train_pred))\n",
    "print(\"\\nReporte testeo:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Reprobado', 'Aprobado'], yticklabels=['Reprobado', 'Aprobado'])\n",
    "plt.title(\"Matriz de Confusión (Test)\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b90067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC y AUC\n",
    "y_test_probs = modelo.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_probs)\n",
    "auc_score = roc_auc_score(y_test, y_test_probs)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"Tasa de Falsos Positivos\")\n",
    "plt.ylabel(\"Tasa de Verdaderos Positivos\")\n",
    "plt.title(\"Curva ROC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
